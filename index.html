<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<h1>Joy Buolamwini</h1>

<h2>A mulher lutando contra o preconceito em algoritmos</h2>

<p>Joy Buolamwini é mestre por Oxford e doutoranda e pesquisadora no MIT e, a partir de sua pesquisa motivada por experiências pessoais de discriminação através de vieses dos algoritmos, ela lançou os projetos Coded Gaze e Algorithmic Justice League, para combater os problemas causados pela tecnologia e algoritmos falsamente objetivos. Ela ainda é co-fundadora do Myavana Hair, sistema de recomendação de produtos, serviços e expertise para cada tipo de cabelo.</p>

<img src="img\joy.jpg" height="300" width="500" alt="">

<p>A descoberta de Joy Buolamwini mudou legislações nos EUA sobre o uso de inteligência artificial no reconhecimento de faces. Netflix/Reprodução</p>

<h3>O documentário da Netflix Coded Bias (2020) é dirigido por Shalini Kantayya e investiga o viés racista e machista da inteligência artificial (IA) por trás dos algoritmos de reconhecimento facial.</h3>

<img src="img\codded bias.jpg" height="300" width="500" alt="">

<p>O enredo poderia fazer parte da série distópica Black Mirror, mas é tema de caloroso debate ético no mundo real.</p>
<p>Pesquisadora do Instituto de Tecnologia de Massachusetts (MIT), Joy Buolamwini apresenta as falhas que descobriu nessa tecnologia na pesquisa que conduz o filme.</p>
<p>Coded Bias mostra como Buolamwini percebeu o problema no reconhecimento facial: em uma tarefa no MIT Media Lab, ela posiciona o rosto em frente a uma tela com dispositivo de inteligência artificial, mas não é reconhecida.</p>
<p>Quando ela coloca uma máscara branca, o sistema consegue detectar.</p>
<p>Assim, a pesquisadora começou a constatar que os programas de inteligência artificial são treinados para identificar padrões baseados em um conjunto de dados (de homens brancos) e, por isso, parecem não reconhecer com precisão faces femininas ou negras.</p>




<body>
    
</body>
</html>